p_val <- rep(1,length(Nnodes))
for (i in 1:length(Nnodes)){
limit[i] <- (1+e)*log(Nnodes)[i]/Nnodes[i]
p_val[i]<- limit[i]+0.0001
}
path_length <- rep(0,length(Nnodes))
repeat_num <- 100
for (j in 1:repeat_num){
for (i in 1:length(Nnodes))
{
g = erdos.renyi.game(Nnodes[i],p_val[i])
avg_path <- average.path.length(g)
if (is.nan(avg_path)){
avg_path <- 0
}
path_length[i] <- path_length[i] + avg_path
}
}
library(igraph)
Nnodes = 2 ^ (seq(0, 10, len=21))
e <- 0.01
p_val <- rep(1,length(Nnodes))
for (i in 1:length(Nnodes)){
limit[i] <- (1+e)*log(Nnodes)[i]/Nnodes[i]
p_val[i]<- limit[i]+0.0001
}
path_length <- rep(0,length(Nnodes))
repeat_num <- 100
for (j in 1:repeat_num){
for (i in 1:length(Nnodes))
{
g = erdos.renyi.game(Nnodes[i],p_val[i])
avg_path <- average.path.length(g)
if (is.nan(avg_path)){
avg_path <- 0
}
path_length[i] <- path_length[i] + avg_path
}
}
library(igraph)
Nnodes = 2 ^ (seq(0, 10, len=21))
e <- 0.01
p_val <- rep(1,length(Nnodes))
for (i in 1:length(Nnodes)){
limit[i] <- (1+e)*log(Nnodes)[i]/Nnodes[i]
p_val[i]<- limit[i]+0.0001
}
limit <- rep(1, length(Nnodes))
for (i in 1:length(Nnodes)){
limit[i] <- (1+e)*log(Nnodes)[i]/Nnodes[i]
p_val[i]<- limit[i]+0.0001
}
path_length <- rep(0,length(Nnodes))
repeat_num <- 100
for (j in 1:repeat_num){
for (i in 1:length(Nnodes))
{
g = erdos.renyi.game(Nnodes[i],p_val[i])
avg_path <- average.path.length(g)
if (is.nan(avg_path)){
avg_path <- 0
}
path_length[i] <- path_length[i] + avg_path
}
}
path_len <- path_length/repeat_num
plot(Nnodes,path_len, ylab = "Average shortest path",
xlab = "num nodes", xlim = c(0,1000), ylim = c(0,max(path_len)),cex.lab = 1.5,type = "b")
library(igraph)
ps <- 10 ^ (-seq(0, 4, len=14))
lens <- rep(1, length(ps))
coefs <- rep(1, length(ps))
repeat_num <- 100
for(k in 1:repeat_num){
for(i in 1:length(ps)) {
wsg <- watts.strogatz.game(1, 100, 5, ps[i])
lens[i] <- lens[i] + (average.path.length(wsg))
coefs[i] <- coefs[i] + (transitivity(wsg))
}
}
lens <- lens/repeat_num
lens <- lens/max(lens)
coefs <- coefs/repeat_num
coefs <- coefs/max(coefs)
df_watts <- data.frame(ps, lens, coefs)
colnames(df_watts) <- c("prob_val", "avg_min_path_length", "coefs")
lens
coefs
ps
library(scales)
library(ggplot2)
shapes  <- c("s1" = 16, "s2" = 0)
# plotting help from
# http://www.sthda.com/english/wiki/ggplot2-axis-scales-and-transformations#display-log-tick-marks
p1 <- ggplot(data=df_watts, aes(df_watts$prob_val)) +
geom_point(aes(y = avg_min_path_length, shape = "s1")) +
geom_point(aes(y = coefs, shape = "s2")) +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
annotation_logticks()  +
labs(x="Probability", y="") +
scale_shape_manual(name = "Sex",
breaks = c("s1", "s2"),
values = shapes,
labels = c("Average shortest path (normalized)", "Clustering coefficient"))
p1
wsg <- watts.strogatz.game(1, 100, 5, 0.01)
wsg <- watts.strogatz.game(1, 100, 5, 0.01)
watts.strogatz.game(1, 100, 5, 0.01)
attributes(watts.strogatz.game(1, 100, 5, 0.01))
### Watts-Strogatz MODEL ##############################################
library(igraph)
ps <- 10 ^ (-seq(0, 4, len=14))
lens <- rep(1, length(ps))
coefs <- rep(1, length(ps))
repeat_num <- 100
for(k in 1:repeat_num){
for(i in 1:length(ps)) {
wsg <- watts.strogatz.game(1, 100, 5, ps[i])
lens[i] <- lens[i] + (average.path.length(wsg))
coefs[i] <- coefs[i] + (transitivity(wsg))
}
}
lens <- lens/repeat_num
lens <- lens/max(lens)
coefs <- coefs/repeat_num
coefs <- coefs/max(coefs)
df_watts <- data.frame(ps, lens, coefs)
colnames(df_watts) <- c("prob_val", "avg_min_path_length", "coefs")
lens
coefs
ps
library(scales)
library(ggplot2)
shapes  <- c("s1" = 16, "s2" = 0)
# plotting help from
# http://www.sthda.com/english/wiki/ggplot2-axis-scales-and-transformations#display-log-tick-marks
p1 <- ggplot(data=df_watts, aes(df_watts$prob_val)) +
geom_point(aes(y = avg_min_path_length, shape = "s1")) +
geom_point(aes(y = coefs, shape = "s2")) +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
annotation_logticks()  +
labs(x="Probability", y="") +
scale_shape_manual(breaks = c("s1", "s2"),
values = shapes,
labels = c("Average shortest path (normalized)", "Clustering coefficient"))
p1
library(igraph)
Nnodes = 2 ^ (seq(0, 10, len=21))
e <- 0.01
p_val <- rep(1,length(Nnodes))
limit <- rep(1, length(Nnodes))
for (i in 1:length(Nnodes)){
limit[i] <- (1+e)*log(Nnodes)[i]/Nnodes[i]
p_val[i]<- limit[i]+0.0001
}
path_length <- rep(0,length(Nnodes))
repeat_num <- 100
for (j in 1:repeat_num){
for (i in 1:length(Nnodes))
{
g = erdos.renyi.game(Nnodes[i],p_val[i])
avg_path <- average.path.length(g)
if (is.nan(avg_path)){
avg_path <- 0
}
path_length[i] <- path_length[i] + avg_path
}
}
path_len <- path_length/repeat_num
plot(Nnodes,path_len, ylab = "Average shortest path",
xlab = "num nodes", xlim = c(0,1000), ylim = c(0,max(path_len)),cex.lab = 1.5,type = "b")
ps
wsg <- watts.strogatz.game(1, 100, 5, 1.0)
wsg
average.path.length(wsg)
### Watts-Strogatz MODEL ##############################################
library(igraph)
ps <- 10 ^ (-seq(0, 4, len=14))
lens <- rep(1, length(ps))
coefs <- rep(1, length(ps))
repeat_num <- 100
for(k in 1:repeat_num){
for(i in 1:length(ps)) {
wsg <- watts.strogatz.game(1, 100, 5, ps[i])
lens[i] <- lens[i] + (average.path.length(wsg))
coefs[i] <- coefs[i] + (transitivity(wsg))
}
}
lens <- lens/repeat_num
lens <- lens/max(lens)
coefs <- coefs/repeat_num
coefs <- coefs/max(coefs)
df_watts <- data.frame(ps, lens, coefs)
colnames(df_watts) <- c("prob_val", "avg_min_path_length", "coefs")
lens
coefs
ps
library(scales)
library(ggplot2)
shapes  <- c("s1" = 16, "s2" = 0)
# plotting help from
# http://www.sthda.com/english/wiki/ggplot2-axis-scales-and-transformations#display-log-tick-marks
p1 <- ggplot(data=df_watts, aes(df_watts$prob_val)) +
geom_point(aes(y = avg_min_path_length, shape = "s1")) +
geom_point(aes(y = coefs, shape = "s2")) +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
annotation_logticks()  +
labs(x="Probability", y="") +
scale_shape_manual(breaks = c("s1", "s2"),
values = shapes,
labels = c("Average shortest path (normalized)", "Clustering coefficient"))
p1
wsg <- watts.strogatz.game(1, 1000, 4, 1.0)
average.path.length(wsg)
### Watts-Strogatz MODEL ##############################################
library(igraph)
ps <- 10 ^ (-seq(0, 4, len=14))
lens <- rep(1, length(ps))
coefs <- rep(1, length(ps))
repeat_num <- 100
for(k in 1:repeat_num){
for(i in 1:length(ps)) {
wsg <- watts.strogatz.game(1, 1000, 4, ps[i])
lens[i] <- lens[i] + (average.path.length(wsg))
coefs[i] <- coefs[i] + (transitivity(wsg))
}
}
### Watts-Strogatz MODEL ##############################################
library(igraph)
ps <- 10 ^ (-seq(0, 4, len=14))
lens <- rep(1, length(ps))
coefs <- rep(1, length(ps))
repeat_num <- 100
for(k in 1:repeat_num){
for(i in 1:length(ps)) {
wsg <- watts.strogatz.game(1, 1000, 4, ps[i])
lens[i] <- lens[i] + (average.path.length(wsg))
coefs[i] <- coefs[i] + (transitivity(wsg))
}
}
lens <- lens/repeat_num
lens <- lens/max(lens)
coefs <- coefs/repeat_num
coefs <- coefs/max(coefs)
df_watts <- data.frame(ps, lens, coefs)
colnames(df_watts) <- c("prob_val", "avg_min_path_length", "coefs")
lens
coefs
ps
library(scales)
library(ggplot2)
shapes  <- c("s1" = 16, "s2" = 0)
# plotting help from
# http://www.sthda.com/english/wiki/ggplot2-axis-scales-and-transformations#display-log-tick-marks
p1 <- ggplot(data=df_watts, aes(df_watts$prob_val)) +
geom_point(aes(y = avg_min_path_length, shape = "s1")) +
geom_point(aes(y = coefs, shape = "s2")) +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
annotation_logticks()  +
labs(x="Probability", y="") +
scale_shape_manual(breaks = c("s1", "s2"),
values = shapes,
labels = c("Average shortest path (normalized)", "Clustering coefficient"))
p1
### Watts-Strogatz MODEL ##############################################
library(igraph)
ps <- 10 ^ (-seq(0, 4, len=14))
lens <- rep(1, length(ps))
coefs <- rep(1, length(ps))
repeat_num <- 100
for(k in 1:repeat_num){
for(i in 1:length(ps)) {
wsg <- watts.strogatz.game(1, 1000, 5, ps[i])
lens[i] <- lens[i] + (average.path.length(wsg))
coefs[i] <- coefs[i] + (transitivity(wsg))
}
}
lens <- lens/repeat_num
lens <- lens/max(lens)
coefs <- coefs/repeat_num
coefs <- coefs/max(coefs)
df_watts <- data.frame(ps, lens, coefs)
colnames(df_watts) <- c("prob_val", "avg_min_path_length", "coefs")
lens
coefs
ps
library(scales)
library(ggplot2)
shapes  <- c("s1" = 16, "s2" = 0)
# plotting help from
# http://www.sthda.com/english/wiki/ggplot2-axis-scales-and-transformations#display-log-tick-marks
p1 <- ggplot(data=df_watts, aes(df_watts$prob_val)) +
geom_point(aes(y = avg_min_path_length, shape = "s1")) +
geom_point(aes(y = coefs, shape = "s2")) +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
annotation_logticks()  +
labs(x="Probability", y="") +
scale_shape_manual(breaks = c("s1", "s2"),
values = shapes,
labels = c("Average shortest path (normalized)", "Clustering coefficient"))
p1
library(scales)
library(ggplot2)
shapes  <- c("s1" = 16, "s2" = 0)
# plotting help from
# http://www.sthda.com/english/wiki/ggplot2-axis-scales-and-transformations#display-log-tick-marks
p1 <- ggplot(data=df_watts, aes(df_watts$prob_val)) +
geom_point(aes(y = avg_min_path_length, shape = "s1")) +
geom_point(aes(y = coefs, shape = "s2")) +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
annotation_logticks()  +
labs(x="Probability", y="") +
scale_shape_manual(name= "",
breaks = c("s1", "s2"),
values = shapes,
labels = c("Average shortest path (normalized)", "Clustering coefficient"))
p1
ps <- 10 ^ (-seq(0, 4, len=14))
lens <- rep(1, length(ps))
coefs <- rep(1, length(ps))
repeat_num <- 100
for(k in 1:repeat_num){
for(i in 1:length(ps)) {
wsg <- watts.strogatz.game(1, 1000, 4, ps[i])
lens[i] <- lens[i] + (average.path.length(wsg))
coefs[i] <- coefs[i] + (transitivity(wsg))
}
}
lens <- lens/repeat_num
lens <- lens/max(lens)
coefs <- coefs/repeat_num
coefs <- coefs/max(coefs)
df_watts <- data.frame(ps, lens, coefs)
colnames(df_watts) <- c("prob_val", "avg_min_path_length", "coefs")
lens
coefs
ps
library(scales)
library(ggplot2)
shapes  <- c("s1" = 16, "s2" = 0)
# plotting help from
# http://www.sthda.com/english/wiki/ggplot2-axis-scales-and-transformations#display-log-tick-marks
p1 <- ggplot(data=df_watts, aes(df_watts$prob_val)) +
geom_point(aes(y = avg_min_path_length, shape = "s1")) +
geom_point(aes(y = coefs, shape = "s2")) +
scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) +
annotation_logticks()  +
labs(x="Probability", y="") +
scale_shape_manual(name= "",
breaks = c("s1", "s2"),
values = shapes,
labels = c("Average shortest path (normalized)", "Clustering coefficient"))
p1
library(igraph)
Nnodes = 2 ^ (seq(0, 10, len=21))
e <- 0.01
p_val <- rep(1,length(Nnodes))
limit <- rep(1, length(Nnodes))
for (i in 1:length(Nnodes)){
limit[i] <- (1+e)*log(Nnodes)[i]/Nnodes[i]
p_val[i]<- limit[i]+0.0001
}
path_length <- rep(0,length(Nnodes))
repeat_num <- 100
for (j in 1:repeat_num){
for (i in 1:length(Nnodes))
{
g = erdos.renyi.game(Nnodes[i],p_val[i])
avg_path <- average.path.length(g)
if (is.nan(avg_path)){
avg_path <- 0
}
path_length[i] <- path_length[i] + avg_path
print(path_length)
}
}
path_len <- path_length/repeat_num
plot(Nnodes,path_len, ylab = "Average shortest path",
xlab = "num nodes", xlim = c(0,1000), ylim = c(0,max(path_len)),cex.lab = 1.5,type = "b")
qqnorm(pvalues)
setwd("C:/Users/Philosoraptor/Dropbox/2017kool/StatisticalGenetics/upc-bioinformatics")
# 1) Load the data
library(genetics)
library(HardyWeinberg)
filename = "YRIChr1.rda"
load(filename)
#x <- X # for faster typing
# 2) How many individuals does the database contain?
nrow(X)
# 2) What percentage of the variants is monomorphic?
monomorphic <- ncol(Filter(function(y)(length(unique(y))==1), X))
monomorphic / ncol(X) * 100
#69.65%
# 2) Remove all monomorphic SNPs from the data bases. How many variants remain in the
# database?
heteromorphic <- Filter(function(y)(length(unique(y))>1), X)
ncol(heteromorphic) # 3035
#Determine the genotype counts for these variants, and store them in matrix.
geno <- data.frame(matrix(ncol = ncol(heteromorphic), nrow = 3))
colnames_geno <- colnames(heteromorphic)
colnames(geno) <- colnames_geno
rownames(geno) <- c("AA", "AB", "BB")
for(name in colnames(heteromorphic)){
geno[1, name] <- dim(subset(X[name], X[name] == 0))[1]
geno[2, name] <- dim(subset(X[name], X[name] == 1))[1]
geno[3, name] <- dim(subset(X[name], X[name] == 2))[1]
}
# 2) Apply a chi-square test without continuity correction for
# Hardy-Weinberg equilibrium to each SNP.
# transform the geno matrix so that cols are AA, AB, BB and row variants (loci)
geno_transposed <- as.data.frame(t(geno))
# add chi p value column
geno_transposed$chi_p <- NA
# calc chi values
for(i in 1:dim(geno_transposed)[1]){
num_vector <- as.numeric(geno_transposed[i, 1:3])
names(num_vector) <- c("AA", "AB", "BB")
chiStatistics <- HWChisq(num_vector,cc=0)
geno_transposed$chi_p[i] <- chiStatistics[2]
geno_transposed$allelle_f[i] <- chiStatistics[4]
}
# 2) How many SNPs are significant (use ?? = 0.05)?
nrow(subset(geno_transposed, geno_transposed$chi_p < 0.05))
# 3) How many markers of the remaining non-monomorphic markers would you expect to be out
# of equilibrium by the effect of chance alone?
nrow(geno_transposed) * 0.05
# 4) Apply an Exact test for Hardy-Weinberg equilibrium to each SNP. You can use function
# HWExactStats for fast computation.
geno_transposed$HWExact <- HWExactStats(geno_transposed[,1:3])
# 4) How many SNPs are significant (use ?? = 0.05). Is the result
# consistent with the chi-square test?
nrow(subset(geno_transposed, geno_transposed$HWExact < 0.05))
# No, the results are a little different:
# chi significant: 160
# exact significant. 126.
# But compared to 3035 non-monomorfic markers it's insignificant difference, so in general results are consistent.
#Chi test is closer to expected amount out of equilibrium
# 5) Apply a likelihood ratio test for Hardy-Weinberg equilibrium to each SNP, using the HWLratio function.
# add HWLratio column
geno_transposed$HWLratio <- NA
# calc HWLratio values
for(i in 1:dim(geno_transposed)[1]){
num_vector <- as.numeric(geno_transposed[i, 1:3])
names(num_vector) <- c("AA", "AB", "BB")
geno_transposed$HWLratio[i] <- as.numeric(HWLratio(num_vector)[1])
}
# How many SNPs are significant (use ?? = 0.05). Is the result consistent with the chi-square test?
geno_transposed$HWLratio_p <- NA
for(i in 1:dim(geno_transposed)[1]){
num_vector <- as.numeric(geno_transposed[i, 1:3])
names(num_vector) <- c("AA", "AB", "BB")
geno_transposed$HWLratio_p[i] <- as.numeric(HWLratio(num_vector)[3])
}
nrow(subset(geno_transposed, geno_transposed$HWLratio_p < 0.05))
# 145, result is almost consistent with the chi-square test of 160
# delete this useless column
geno_transposed$HWLratio_p <- NULL
# 6) Apply a permutation test for Hardy-Weinberg equilibrium to the first 10 SNPs, using the
# classical chi-square test (without continuity correction) as a test statistic.
# add HWPerm column
geno_transposed$HWPerm_p <- NA
# calc HWPerm values
for(i in 1:10){
num_vector <- as.numeric(geno_transposed[i, 1:3])
names(num_vector) <- c("AA", "AB", "BB")
geno_transposed$HWPerm_p[i] <- HWPerm(num_vector, nperm = 1000)[2]
}
# 6) List the 10 p-values, together with the 10 p-values of the exact tests. Are the result consistent?
tmp <- geno_transposed[1:10,]
tmp$p_perm = geno_transposed[1:10,]$HWPerm_p
tmp$p_val<-NULL
# In this case the values are consistent
# 7)  Depict all SNPs simultaeneously in a ternary plot, and comment on your result (because many
# genotype counts repeat, you may use UniqueGenotypeCounts to speed up the computations)
SNPs_geno <-  geno_transposed[,1:3]
SNPs_geno <- UniqueGenotypeCounts(SNPs_geno)[1:3]
HWTernaryPlot(SNPs_geno)
# It seems as if most of the variants in the database follow the boundaries of Hardy-Weinberg equilibrium
# Also, we can notice that the BB-homozygotes don't dominate at all - they are a numerical minority in
# all genotype counts
# 8) Can you explain why half of the ternary diagram is empty?
A <- sum(geno_transposed[,1]) + 0.5*sum(geno_transposed[,2])
B <- sum(geno_transposed[,3]) + 0.5*sum(geno_transposed[,2])
A/B
# There are much more B-alleles in the dataset, 11.13 times more, to be exact. In no examples of the genotype counts
# do number of B-alleles surpass that of A-alleles
# 9) Make a histogram of the p-values obtained in the chi-square test
# chi vector stores p-val from HWChisq
pvalues <- unlist(geno_transposed$chi_p)
hist(pvalues, breaks=20)
# 9) What distribution would you expect if HWE would hold for the data set? What distribution do you observe?
# if pval < 0.05 then it's unlikely that genotype differences are due to chance.
#Beta distribution could be possible one. Null distribution or uniform?
# 9) make a Q-Q plot of the p values obtained in the chi-square test against the quantiles of the distribution that you consider relevant.
qqnorm(pvalues)
qqline(pvalues,  datax = FALSE, distribution = qlogis() ,probs = c(0.25, 0.75), qtype = 7)
# 9) What is your conclusion?
qqline(pvalues,  datax = FALSE, distribution = qlogis() ,probs = c(0.25, 0.75), qtype = 7)
qqline(pvalues,  datax = FALSE, distribution = qlogis() ,p = c(0.25, 0.75), qtype = 7)
robs
qqline(pvalues,  datax = FALSE, distribution = qlogis() ,probs = c(0.25, 0.75), qtype = 7)
hist(pvalues, breaks=20)
hist(pvalues, breaks=100)
hist(pvalues, breaks=20)
qqnorm(pvalues)
